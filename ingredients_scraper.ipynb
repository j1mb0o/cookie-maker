{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the href_set.txt file and save the hrefs in a list\n",
    "urls = []\n",
    "with open('href_set.txt', 'r') as f:\n",
    "    for line in f:\n",
    "        urls.append(line.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_ingredients(url):\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "    # Find the title of the recipe\n",
    "    title = soup.find('title').get_text().strip()\n",
    "\n",
    "    # Try to find the ingredients section by looking for \"Ingredients\" header\n",
    "    ingredients = []\n",
    "    \n",
    "    # Look for the header that contains \"Ingredients\"\n",
    "    ingredients_section = soup.find(lambda tag: tag.name.startswith('h') and 'ingredient' in tag.get_text().lower())\n",
    "    \n",
    "    if ingredients_section:\n",
    "        # Try finding an unordered list (<ul>) or ordered list (<ol>) immediately following the header\n",
    "        ingredients_list = ingredients_section.find_next('ul') or ingredients_section.find_next('ol')\n",
    "\n",
    "        if ingredients_list:\n",
    "            # Extract the ingredients from the list items\n",
    "            ingredients = [li.get_text().strip() for li in ingredients_list.find_all('li')]\n",
    "        else:\n",
    "            # Backup: try to find ingredients in nearby <p> tags\n",
    "            ingredients_paragraphs = ingredients_section.find_next_siblings('p', limit=10)\n",
    "            for paragraph in ingredients_paragraphs:\n",
    "                ingredients.append(paragraph.get_text().strip())\n",
    "    \n",
    "    return title, ingredients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('cookie_ingredients.txt', 'w') as file:\n",
    "    for url in urls:\n",
    "        try:\n",
    "            name, ingredients = scrape_ingredients(url)\n",
    "            if ingredients:\n",
    "                file.write(f'{name}, {\", \".join(ingredients)}\\n')\n",
    "            else:\n",
    "                file.write(f'{name}, No ingredients found\\n')\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to scrape {url}: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
